{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter vs Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning models are parameterized so that their behavior can be tuned for a given problem. Models can have many parameters and finding the best combination of parameters can be treated as a search problem.\n",
    " \n",
    "Grid search is an approach to parameter tuning that will methodically build and evaluate a model for each combination of algorithm parameters specified in a grid.\n",
    "\n",
    "The following code evaluates different alpha values for the Ridge Regression algorithm on the diabetes dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grid Search for Algorithm Tuning\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# load the diabetes datasets\n",
    "dataset = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the Grid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare a range of alpha values to test\n",
    "alphas = np.array([1,0.1,0.01,0.001,0.0001,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform the Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': array([  1.00000e+00,   1.00000e-01,   1.00000e-02,   1.00000e-03,\n",
      "         1.00000e-04,   0.00000e+00])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# create and fit a ridge regression model, testing each alpha\n",
    "model = Ridge()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "grid.fit(dataset.data, dataset.target)\n",
    "\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.488790204461\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random search is an approach to parameter tuning that will sample algorithm parameters from a random distribution (i.e. uniform) for a fixed number of iterations. A model is constructed and evaluated for each combination of parameters chosen. \n",
    " \n",
    "The following code evaluates different alpha random values between 0 and 1 for the Ridge Regression algorithm on the diabetes dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomized Search for Algorithm Tuning\n",
    "import numpy as np\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "# load the diabetes datasets\n",
    "dataset = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare a uniform distribution to sample for the alpha parameter\n",
    "param_grid = {'alpha': sp_rand()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform the Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=None, error_score='raise',\n",
      "          estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
      "          fit_params={}, iid=True, n_iter=100, n_jobs=1,\n",
      "          param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x10427bcf8>},\n",
      "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "          scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# create and fit a ridge regression model, testing random alpha values\n",
    "model = Ridge()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100)\n",
    "rsearch.fit(dataset.data, dataset.target)\n",
    "print(rsearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.489165385076\n",
      "0.055347884724043395\n"
     ]
    }
   ],
   "source": [
    "# summarize the results of the random parameter search\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search vs Random Search: Which one is better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf\n",
    "* https://medium.com/rants-on-machine-learning/smarter-parameter-sweeps-or-why-grid-search-is-plain-stupid-c17d97a0e881#.z27w2p3sr\n",
    "* http://scikit-learn.org/stable/auto_examples/model_selection/randomized_search.html\n",
    "* Hyperparameter Tuning - http://blog.sigopt.com/post/144221180573/evaluating-hyperparameter-optimization-strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 10.78 seconds for 100 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.931 (std: 0.014)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'entropy', 'max_features': 4, 'min_samples_leaf': 3, 'max_depth': None, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.930 (std: 0.011)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_features': 8, 'min_samples_leaf': 4, 'max_depth': None, 'min_samples_split': 7}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.927 (std: 0.011)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_features': 8, 'min_samples_leaf': 3, 'max_depth': None, 'min_samples_split': 2}\n",
      "\n",
      "GridSearchCV took 21.07 seconds for 216 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.939 (std: 0.006)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_features': 10, 'min_samples_leaf': 1, 'max_depth': None, 'min_samples_split': 3}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.937 (std: 0.012)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_features': 10, 'min_samples_leaf': 1, 'max_depth': None, 'min_samples_split': 1}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.933 (std: 0.014)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_features': 3, 'min_samples_leaf': 1, 'max_depth': None, 'min_samples_split': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# get some data\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# build a classifier\n",
    "clf = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(1, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 100\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.grid_scores_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [1, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.grid_scores_)))\n",
    "report(grid_search.grid_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The randomized search and the grid search explore exactly the same space of parameters.\n",
    "* The result in parameter settings is quite similar, while the run time for randomized search can be drastically lower.\n",
    "* The performance is slightly worse for the randomized search, though this is most likely a noise effect and would not carry over to a held-out test set.\n",
    "* Note that in practice, one would not search over this many different parameters simultaneously using grid search, but pick only the ones deemed most important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Estimation with grid search and cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* development set comprises only half of the available labeled data\n",
    "* the performance of the selected hyper-parameters and trained model is then measured on a dedicated evaluation set that was not used during the model selection step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 0.001, 'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.987 (+/-0.018) for {'gamma': 0.001, 'C': 1, 'kernel': 'rbf'}\n",
      "0.959 (+/-0.030) for {'gamma': 0.0001, 'C': 1, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.018) for {'gamma': 0.001, 'C': 10, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.027) for {'gamma': 0.0001, 'C': 10, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.018) for {'gamma': 0.001, 'C': 100, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.026) for {'gamma': 0.0001, 'C': 100, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.018) for {'gamma': 0.001, 'C': 1000, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.026) for {'gamma': 0.0001, 'C': 1000, 'kernel': 'rbf'}\n",
      "0.974 (+/-0.014) for {'kernel': 'linear', 'C': 1}\n",
      "0.974 (+/-0.014) for {'kernel': 'linear', 'C': 10}\n",
      "0.974 (+/-0.014) for {'kernel': 'linear', 'C': 100}\n",
      "0.974 (+/-0.014) for {'kernel': 'linear', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        89\n",
      "          1       0.97      1.00      0.98        90\n",
      "          2       0.99      0.98      0.98        92\n",
      "          3       1.00      0.99      0.99        93\n",
      "          4       1.00      1.00      1.00        76\n",
      "          5       0.99      0.98      0.99       108\n",
      "          6       0.99      1.00      0.99        89\n",
      "          7       0.99      1.00      0.99        78\n",
      "          8       1.00      0.98      0.99        92\n",
      "          9       0.99      0.99      0.99        92\n",
      "\n",
      "avg / total       0.99      0.99      0.99       899\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 0.001, 'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.986 (+/-0.021) for {'gamma': 0.001, 'C': 1, 'kernel': 'rbf'}\n",
      "0.958 (+/-0.029) for {'gamma': 0.0001, 'C': 1, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.021) for {'gamma': 0.001, 'C': 10, 'kernel': 'rbf'}\n",
      "0.981 (+/-0.029) for {'gamma': 0.0001, 'C': 10, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.021) for {'gamma': 0.001, 'C': 100, 'kernel': 'rbf'}\n",
      "0.981 (+/-0.027) for {'gamma': 0.0001, 'C': 100, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.021) for {'gamma': 0.001, 'C': 1000, 'kernel': 'rbf'}\n",
      "0.981 (+/-0.027) for {'gamma': 0.0001, 'C': 1000, 'kernel': 'rbf'}\n",
      "0.973 (+/-0.015) for {'kernel': 'linear', 'C': 1}\n",
      "0.973 (+/-0.015) for {'kernel': 'linear', 'C': 10}\n",
      "0.973 (+/-0.015) for {'kernel': 'linear', 'C': 100}\n",
      "0.973 (+/-0.015) for {'kernel': 'linear', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        89\n",
      "          1       0.97      1.00      0.98        90\n",
      "          2       0.99      0.98      0.98        92\n",
      "          3       1.00      0.99      0.99        93\n",
      "          4       1.00      1.00      1.00        76\n",
      "          5       0.99      0.98      0.99       108\n",
      "          6       0.99      1.00      0.99        89\n",
      "          7       0.99      1.00      0.99        78\n",
      "          8       1.00      0.98      0.99        92\n",
      "          9       0.99      0.99      0.99        92\n",
      "\n",
      "avg / total       0.99      0.99      0.99       899\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Loading the Digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
    "                       scoring='%s_weighted' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    for params, mean_score, scores in clf.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
