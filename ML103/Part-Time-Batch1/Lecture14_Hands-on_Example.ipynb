{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# load the iris dataset\n",
    "iris = load_iris()\n",
    "print(iris.data.shape)\n",
    "\n",
    "# separate the data from the target attributes\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization refers to rescaling real valued numeric attributes into the range 0 and 1. It is useful to scale the input attributes for a model that relies on the magnitude of values, such as distance measures used in kÂ­nearest neighbors and in the preparation of coefficients in regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize the data attributes\n",
    "normalized_X = preprocessing.normalize(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization refers to shifting the distribution of each attribute to have a mean of 0 and a standard deviation of 1. It is useful to standardize attributes for a model that relies on the distribution of attributes such as Gaussian processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize the data attributes\n",
    "standardized_X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data can have missing values. \n",
    "* These are values for attributes where a measurement could not be taken or is corrupt for some reason.\n",
    "* It is important to identify and mark this missing data. Once marked, replacement values can be prepared.\n",
    "* This is useful because some algorithms are unable to work with or exploit missing data.  \n",
    " \n",
    "The following code demonstrates marking 0 values from the Pima Indians dataset as NaN and imputing the missing values with the mean of the attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "# Mark 0 values as missing and impute with the mean\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Load the Pima Indians Diabetes dataset\n",
    "url = \"http://goo.gl/j0Rvxq\"\n",
    "raw_data = urllib.request.urlopen(url)\n",
    "dataset = np.loadtxt(raw_data, delimiter=\",\")\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   6.   ,  148.   ,   72.   , ...,      nan,   33.6  ,    0.627],\n",
       "       [   1.   ,   85.   ,   66.   , ...,      nan,   26.6  ,    0.351],\n",
       "       [   8.   ,  183.   ,   64.   , ...,      nan,   23.3  ,    0.672],\n",
       "       ..., \n",
       "       [   5.   ,  121.   ,   72.   , ...,  112.   ,   26.2  ,    0.245],\n",
       "       [   1.   ,  126.   ,   60.   , ...,      nan,   30.1  ,    0.349],\n",
       "       [   1.   ,   93.   ,   70.   , ...,      nan,   30.4  ,    0.315]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate the data and target attributes\n",
    "X = dataset[:,0:7]\n",
    "y = dataset[:,8]\n",
    "\n",
    "# Mark all zero values as NaN\n",
    "X[X==0] = np.nan\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   6.        ,  148.        ,   72.        , ...,  155.54822335,\n",
       "          33.6       ,    0.627     ],\n",
       "       [   1.        ,   85.        ,   66.        , ...,  155.54822335,\n",
       "          26.6       ,    0.351     ],\n",
       "       [   8.        ,  183.        ,   64.        , ...,  155.54822335,\n",
       "          23.3       ,    0.672     ],\n",
       "       ..., \n",
       "       [   5.        ,  121.        ,   72.        , ...,  112.        ,\n",
       "          26.2       ,    0.245     ],\n",
       "       [   1.        ,  126.        ,   60.        , ...,  155.54822335,\n",
       "          30.1       ,    0.349     ],\n",
       "       [   1.        ,   93.        ,   70.        , ...,  155.54822335,\n",
       "          30.4       ,    0.315     ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute all missing values with the mean of the attribute\n",
    "imp = Imputer(missing_values='NaN', strategy='mean')\n",
    "imputed_X = imp.fit_transform(X)\n",
    "\n",
    "imputed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Classical Regression\n",
    "* Handling Nonlinearity\n",
    "* Regularization\n",
    "* Dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# load the diabetes datasets\n",
    "dataset = datasets.load_diabetes()\n",
    "\n",
    "# fit a linear regression model to the data\n",
    "model = LinearRegression()\n",
    "model.fit(dataset.data, dataset.target)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2859.69039877\n",
      "0.517749425413\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "expected = dataset.target\n",
    "predicted = model.predict(dataset.data)\n",
    "\n",
    "# summarize the fit of the model\n",
    "mse = np.mean((predicted-expected)**2)\n",
    "print(mse)\n",
    "print(model.score(dataset.data, dataset.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *score* returns the *R^2* of the model (http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "* generally, higher the *score*, the better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Logistic regression fits a logistic model to data and makes predictions about the probability of an event (between 0 and 1)\n",
    "\n",
    "We show the fitting of a logistic regression algorithm to the iris dataset. Because this is a mutliclass classification problem and logistic regression makes predictions between 0 and 1, a one-vs-all scheme is used (one model is created per class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "# fit a logistic regression model to the data\n",
    "model = LogisticRegression()\n",
    "model.fit(dataset.data, dataset.target)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        50\n",
      "          1       0.98      0.90      0.94        50\n",
      "          2       0.91      0.98      0.94        50\n",
      "\n",
      "avg / total       0.96      0.96      0.96       150\n",
      "\n",
      "[[50  0  0]\n",
      " [ 0 45  5]\n",
      " [ 0  1 49]]\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "expected = dataset.target\n",
    "predicted = model.predict(dataset.data)\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
