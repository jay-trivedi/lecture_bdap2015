{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Univariate Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing features with low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We want to remove all features whose variance doesnâ€™t meet some threshold\n",
    "* For example, we should remove all zero-variance features, i.e. features that have the same value in all samples\n",
    "* As an example, suppose that we have a dataset with boolean features, and we want to remove all features that are either one or zero (on or off) in more than 80% of the samples\n",
    "* Boolean features are Bernoulli random variables, and the variance of such variables is given by $Var[x] = p(1-p)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "X = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the first column is gone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Recursive Feature Elimination (RFE) method is a feature selection approach. It works by recursively removing attributes and building a model on those attributes that remain. It uses the model accuracy to identify which attributes (and combination of attributes) contribute the most to predicting the target attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True  True]\n",
      "[2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "# create a base classifier used to evaluate a subset of attributes\n",
    "model = LogisticRegression()\n",
    "\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(model, 3)\n",
    "rfe = rfe.fit(dataset.data, dataset.target)\n",
    "\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods that use ensembles of decision trees (like Random Forest and Extra Trees) can also compute the relative importance of each attribute. These importance values can be used to inform a feature selection process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.07268384  0.07023344  0.38643323  0.47064949]\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "# fit an Extra Trees model to the data\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(dataset.data, dataset.target)\n",
    "\n",
    "# display the relative importance of each attribute\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SelectKBest: removes all but the k highest scoring features\n",
    "* SelectPercentile: removes all but a user-specified highest scoring percentage of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0463850883112\n",
      "0.930422367533\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(dataset.data, dataset.target)\n",
    "expected = dataset.target\n",
    "predicted = model.predict(dataset.data)\n",
    "\n",
    "# summarize the fit of the model\n",
    "mse = np.mean((predicted-expected)**2)\n",
    "print(mse)\n",
    "print(model.score(dataset.data, dataset.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0465592211731\n",
      "0.93016116824\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "X_new = SelectKBest(chi2, k=3).fit_transform(X, y)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_new, dataset.target)\n",
    "expected = dataset.target\n",
    "predicted = model.predict(X_new)\n",
    "\n",
    "# summarize the fit of the model\n",
    "mse = np.mean((predicted-expected)**2)\n",
    "print(mse)\n",
    "print(model.score(X_new, dataset.target))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
